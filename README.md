# Home Credit Default Risk â€” Machine Learning Project
![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python)
![Jupyter](https://img.shields.io/badge/Notebook-Jupyter-orange?logo=jupyter)
![LightGBM](https://img.shields.io/badge/Model-LightGBM-success?logo=leaflet)
![Explainability](https://img.shields.io/badge/Explainability-SHAP-purple)
![Status](https://img.shields.io/badge/Status-In%20Progress-yellow)
![Kaggle](https://img.shields.io/badge/Kaggle-Competition-blue?logo=kaggle)

**Project Description ğŸš§  
A complete endâ€‘toâ€‘end machine learning pipeline for predicting loan default risk using the Kaggle **Home Credit Default Risk** dataset.  
The project combines data engineering, modeling, explainability, and business reasoning to support safer and more inclusive lending decisions.

---

## 1. Problem Statement

> How can we accurately predict a loan applicantâ€™s repayment ability using alternative data sources, in order to broaden financial inclusion while managing lending risk?

Home Credit aims to serve clients with limited or no credit history. Traditional credit scoring often fails these applicants, leading to unnecessary rejections and missed opportunities.  
This project builds a predictive model that estimates default probability using rich behavioral and financial data.

---

## 2. Success Metrics

### ML Metric â€” ROCâ€‘AUC
Chosen because it:
- Handles **class imbalance** effectively  
- Measures **ranking ability**, not just classification  
- Reflects how well the model separates risky vs safe applicants  

**Success Criterion:**  
A model is considered successful if it achieves **ROCâ€‘AUC â‰¥ 0.75** on the holdout test set.

### Business Metrics
Two error types matter:

- **False Positive (Predict Repaid â†’ Actually Default)**  
  â†’ Most costly: leads to financial loss.

- **False Negative (Predict Default â†’ Actually Repaid)**  
  â†’ Missed opportunity: reduces revenue and harms financial inclusion.

A good model minimizes both, with the final threshold chosen based on business tradeâ€‘offs.

---

## 3. Dataset Overview

Source: Kaggle â€” *Home Credit Default Risk*  
The dataset includes demographic, financial, and behavioral data across multiple relational tables.

### Main Table
`application_train.csv` / `application_test.csv`  
- One row per loan application  
- Contains demographics, income, credit amounts, loan details  
- `TARGET`:  
  - `1` â†’ Default  
  - `0` â†’ Repaid  

### Auxiliary Tables
Used for feature engineering (oneâ€‘toâ€‘many relationships):

- `bureau.csv`, `bureau_balance.csv` â€” external credit history  
- `previous_application.csv` â€” past Home Credit loans  
- `POS_CASH_balance.csv` â€” POS/cash loan history  
- `credit_card_balance.csv` â€” credit card usage  
- `installments_payments.csv` â€” repayment behavior  

### Key Challenges
- Highly imbalanced dataset  
- Heavy feature engineering required  
- Multiple relational tables requiring aggregation  

---

## 4. Project Structure

```
JSJ-ML-Project-Home-Credit-default-risk/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/          # Raw Kaggle data (ignored in Git)
â”‚   â””â”€â”€ processed/    # Preprocessed datasets
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_preprocessing.ipynb
â”‚   â”œâ”€â”€ 04_lightgbm_model.ipynb
â”‚   â”œâ”€â”€ 05_shap_explainability.ipynb
â”‚   â”œâ”€â”€ 06_threshold_analysis.ipynb
â”‚   â””â”€â”€ 07_submission.ipynb
â”‚
â”œâ”€â”€ models/           # Saved model files (e.g., lightgbm_model.pkl)
â”œâ”€â”€ submissions/      # Kaggle submission files
â”œâ”€â”€ src/              # Optional scripts
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## 5. Getting Started

### Prerequisites
- Python 3.11.3  
- `pip`
- `pyenv` (optional but recommended)

---

### Installation

#### macOS
```bash
pyenv local 3.11.3
python -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

#### Windows (PowerShell)
```powershell
pyenv local 3.11.3
python -m venv .venv
.venv\Scripts\Activate.ps1
pip install --upgrade pip
pip install -r requirements.txt
```

---

## 6. Data Setup

âš ï¸ **Important:** The dataset is too large for GitHub.  
You must download it manually.

### Option A â€” Raw Kaggle Data (Full Pipeline)
Download from Kaggle and place all `.csv` files into:

```
data/raw/
```

### Option B â€” Preprocessed Data (Recommended)
Download from Google Drive:  
https://drive.google.com/drive/folders/1sF8oaBiNfejXVH303rNFqUEFYP85arG0?usp=drive_link

Place files into:

```
data/processed/
```

---

## 7. Usage

Run the notebooks in the following order:

1. `01_eda.ipynb` â€” Exploratory data analysis  
2. `02_feature_engineering.ipynb` â€” Aggregations and feature creation  
3. `03_preprocessing.ipynb` â€” Cleaning, encoding, and preparing the dataset  
4. `04_lightgbm_model.ipynb` â€” Training the LightGBM model  
5. `05_shap_explainability.ipynb` â€” SHAP global and local interpretability  
6. `06_threshold_analysis.ipynb` â€” Business-driven threshold selection  
7. `07_submission.ipynb` â€” Generate final predictions for Kaggle submission  

Model outputs are saved in:

```
models/lightgbm_model.pkl
```

---

## 8. Roadmap

### Phase 1 â€” Problem Framing
Define business context, personas, metrics, constraints.

### Phase 2 â€” Data Understanding
EDA, missing values, correlations, class imbalance.

### Phase 3 â€” Feature Engineering
Aggregations, ratios, domainâ€‘inspired features.

### Phase 4 â€” Modeling
Baseline â†’ LightGBM â†’ tuning â†’ evaluation.

### Phase 5 â€” Explainability
SHAP analysis, risk threshold exploration.

### Phase 6 â€” Delivery
Save model, generate submission, finalize documentation.

---

## 9. Future Improvements
- Hyperparameter tuning  
- Threshold optimization  
- Model deployment pipeline  
- Fairness analysis  
- Automated reporting  
```

## Future Improvements
...

## Contributors
This project was developed as part of a team assignment for the Data Science program.  
Contributions were made by our team across data exploration, modeling, and documentation.

- **Jaideep** â€“ https://github.com/jaideepinberlin741/
- **Sumit** â€“ https://github.com/summyhug
- **Jolanda** â€“ https://github.com/joolanda

## License
This project is licensed under the MIT License. See the LICENSE file for details.

---

