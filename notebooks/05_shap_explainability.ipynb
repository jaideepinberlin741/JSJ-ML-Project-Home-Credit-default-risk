{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "1. Imports & Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import shap\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(\"Loading trained LightGBM model...\")\n",
    "model_path = '../models/lightgbm_model.pkl'\n",
    "lgbm_model = joblib.load(model_path)\n",
    "print(f\"Model loaded successfully from: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "2. Load Final Features & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading final feature dataset...\")\n",
    "final_features_path = '../data/processed/final_train_features.csv'\n",
    "final_features_df = pd.read_csv(final_features_path)\n",
    "print(\"Final features shape:\", final_features_df.shape)\n",
    "\n",
    "# Remove ID and target columns\n",
    "X_test = final_features_df.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
    "print(\"X_test shape (features only):\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: sample for faster SHAP computation\n",
    "# X_test = X_test.sample(n=5000, random_state=42)\n",
    "# print(\"Sampled X_test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "3. Restore Categorical Dtypes (Critical Step)\n",
    "\n",
    "LightGBM stored the category lists in lgbm_model.pandas_categorical.\n",
    "We must convert the corresponding columns back to category dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all object columns to category dtype\n",
    "object_cols = X_test.select_dtypes(include='object').columns\n",
    "\n",
    "print(\"Converting object columns to category dtype:\", list(object_cols))\n",
    "\n",
    "for col in object_cols:\n",
    "    X_test[col] = X_test[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "4. Initialize SHAP TreeExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing SHAP TreeExplainer...\")\n",
    "explainer = shap.TreeExplainer(lgbm_model)\n",
    "print(\"SHAP TreeExplainer initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "5. Compute SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating SHAP values... (this may take a while)\")\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "print(\"SHAP values calculated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Select the positive class (LightGBM often returns a list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(shap_values, list):\n",
    "    shap_values_to_use = shap_values[1]\n",
    "else:\n",
    "    shap_values_to_use = shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feature = X_test.columns[0]\n",
    "shap.dependence_plot(top_feature, shap_values_to_use, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## ðŸ” SHAP Dependence Plot: NAME_CONTRACT_TYPE\n",
    "\n",
    "This plot shows how the feature `NAME_CONTRACT_TYPE` influences the model's prediction, with color representing the value of `AMT_ANNUITY`.\n",
    "\n",
    "### Key insights:\n",
    "- **Revolving loans** tend to have **more negative SHAP values**, meaning they push the prediction toward default more strongly than cash loans.\n",
    "- **Cash loans** show a wider spread of SHAP values, suggesting their impact depends more on other features (like annuity size).\n",
    "- The color gradient (blue â†’ pink) reflects `AMT_ANNUITY`:\n",
    "  - **Higher annuities (pink)** are more common among **cash loans**\n",
    "  - **Lower annuities (blue)** dominate among **revolving loans**\n",
    "\n",
    "### Interpretation:\n",
    "- The model has learned that **revolving loans are riskier**, regardless of annuity size.\n",
    "- For **cash loans**, the annuity amount plays a more nuanced role in shaping risk.\n",
    "\n",
    "This plot reveals a clear interaction between loan type and annuity size, helping us understand how the model weighs different financial profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "6. SHAP Visualizations\n",
    "\n",
    "Now, we will initialize the SHAP explainer and calculate the SHAP values for each feature and each prediction. We use `TreeExplainer` as it is highly optimized for tree-based models like LightGBM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "6.1 Global feature importance (summary plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_to_use, X_test, max_display=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## ðŸ“Š SHAP Summary & Dependence Plot Insights\n",
    "\n",
    "### ðŸ”¹ SHAP Summary Plot\n",
    "\n",
    "This plot ranks the top features by their overall impact on the model's predictions. Each dot represents a SHAP value for one instance, colored by the feature value (blue = low, red = high).\n",
    "\n",
    "**Key insights:**\n",
    "- `EXT_SOURCE_2` and `EXT_SOURCE_3` are the most influential features, with higher values (red) pushing predictions toward non-default.\n",
    "- `CODE_GENDER`, `DAYS_BIRTH`, and `DAYS_EMPLOYED` show strong directional effects â€” older age and longer employment reduce risk.\n",
    "- Financial features like `AMT_CREDIT`, `AMT_GOODS_PRICE`, and `AMT_ANNUITY` have nuanced effects depending on context.\n",
    "\n",
    "This plot helps identify which features dominate the modelâ€™s decision-making and how their values influence outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "6.2 Dependence plot for a top feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feature = X_test.columns[0]\n",
    "shap.dependence_plot(top_feature, shap_values_to_use, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### ðŸ”¹ SHAP Dependence Plot: NAME_CONTRACT_TYPE\n",
    "\n",
    "This plot shows how `NAME_CONTRACT_TYPE` influences predictions, with color representing `AMT_ANNUITY`.\n",
    "\n",
    "**Key insights:**\n",
    "- **Revolving loans** consistently push predictions toward default (negative SHAP values).\n",
    "- **Cash loans** show a wider spread, with impact depending on annuity size.\n",
    "- Higher annuities (pink) are more common among cash loans, while revolving loans tend to have lower annuities (blue).\n",
    "\n",
    "This reveals a clear interaction: loan type and annuity size jointly shape risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "1. Dependence Plots for Top Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"EXT_SOURCE_2\", shap_values_to_use, X_test)\n",
    "shap.dependence_plot(\"DAYS_BIRTH\", shap_values_to_use, X_test)\n",
    "shap.dependence_plot(\"AMT_CREDIT\", shap_values_to_use, X_test)\n",
    "shap.dependence_plot(\"ORGANIZATION_TYPE\", shap_values_to_use, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## ðŸ” SHAP Dependence Plots: EXT_SOURCE_2, DAYS_BIRTH, AMT_CREDIT, ORGANIZATION_TYPE\n",
    "\n",
    "### ðŸ”¹ EXT_SOURCE_2\n",
    "This feature shows a strong inverse relationship with risk: higher values (to the right) lead to lower SHAP values, meaning reduced predicted risk. The color gradient (based on `BUREAU_DEBT_CREDIT_RATIO`) reveals that clients with high debt-to-credit ratios (pink) tend to have lower EXT_SOURCE_2 scores and higher risk.\n",
    "\n",
    "### ðŸ”¹ DAYS_BIRTH\n",
    "Older clients (more negative values) tend to have lower predicted risk. The color gradient shows gender (`CODE_GENDER`), revealing subtle differences in how age impacts predictions across genders. Younger individuals (closer to 0) are associated with higher SHAP values, indicating increased risk.\n",
    "\n",
    "### ðŸ”¹ AMT_CREDIT\n",
    "This plot shows a nonlinear relationship: very high credit amounts can push predictions both up and down depending on annuity size (`AMT_ANNUITY`, shown in color). The model captures complex interactions between credit and repayment structure.\n",
    "\n",
    "### ðŸ”¹ ORGANIZATION_TYPE\n",
    "Different organization types have distinct risk profiles. Some categories (e.g. `Business Entity Type 3`) consistently push predictions toward default. The color gradient (based on `EXT_SOURCE_2`) shows that lower external scores amplify the negative impact of certain organizations.\n",
    "\n",
    "These plots reveal how individual features interact with others and shape the modelâ€™s decisions â€” a powerful tool for understanding model behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "2. Individual Prediction Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "This section zooms in on a single prediction to show how the model arrived at its decision.\n",
    "\n",
    "We use a SHAP force plot to visualize the contribution of each feature for one client. Features pushing the prediction toward default are shown in red; those pushing away from default are in blue.\n",
    "\n",
    "The base value represents the average model output across all clients. The final prediction is the result of adding/subtracting each featureâ€™s SHAP value.\n",
    "\n",
    "This is especially useful for:\n",
    "- Auditing model decisions\n",
    "- Explaining outcomes to stakeholders\n",
    "- Identifying borderline cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(shap_values, list):\n",
    "    shap_values_to_use = shap_values[1]\n",
    "    expected_value = explainer.expected_value[1]\n",
    "else:\n",
    "    shap_values_to_use = shap_values\n",
    "    expected_value = explainer.expected_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 42\n",
    "shap.force_plot(expected_value, shap_values_to_use[i], X_test.iloc[i], matplotlib=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "More about the SHAP Summary Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "The summary plot is a powerful visualization that combines feature importance with feature effects. Each point on the plot is a Shapley value for a feature and an instance.\n",
    "\n",
    "- **Feature Importance:** Features are ranked in descending order of importance.\n",
    "- **Impact:** The horizontal location shows whether the effect of that value is associated with a higher or lower prediction.\n",
    "- **Original Value:** Color shows whether that feature was high (red) or low (blue) for that instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "8. Risk Threshold Analysis (optional?)\n",
    "\n",
    "The model outputs a probability of default for each client. To turn these probabilities into actionable decisions, we need a threshold â€” a cutoff above which a client is classified as \"high risk.\"\n",
    "\n",
    "This section explores how predictions behave around that threshold and how SHAP values help us understand borderline cases.\n",
    "\n",
    "### Why this matters\n",
    "- A threshold that is too low will flag too many clients as risky.\n",
    "- A threshold that is too high may miss clients who are genuinely at risk.\n",
    "- SHAP values reveal *why* borderline predictions occur and which features drive uncertainty.\n",
    "\n",
    "### What we analyze here\n",
    "1. **Distribution of predicted probabilities**  \n",
    "   Helps visualize how confident the model is across the population.\n",
    "\n",
    "2. **Borderline cases near the threshold**  \n",
    "   We inspect clients whose predicted risk is close to the cutoff.\n",
    "\n",
    "3. **SHAP waterfall plots for borderline clients**  \n",
    "   These show exactly which features push a prediction above or below the threshold.\n",
    "\n",
    "This analysis supports transparent, data-driven decisions about how to set and justify a risk threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 0. Ensure X_test is fully numeric (REQUIRED for SHAP)\n",
    "# ---------------------------------------------------------\n",
    "X_test_encoded = X_test.copy()\n",
    "for col in X_test_encoded.select_dtypes(include=[\"object\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X_test_encoded[col] = le.fit_transform(X_test_encoded[col].astype(str))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Compute SHAP values using LightGBM-safe settings\n",
    "# ---------------------------------------------------------\n",
    "explainer = shap.TreeExplainer(\n",
    "    lgbm_model,\n",
    "    feature_perturbation=\"tree_path_dependent\"\n",
    ")\n",
    "shap_values = explainer(X_test_encoded)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Compute predicted probabilities\n",
    "# ---------------------------------------------------------\n",
    "y_pred_proba = lgbm_model.predict(X_test_encoded)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Plot distribution of predicted probabilities\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(y_pred_proba, bins=50, color='steelblue', edgecolor='black')\n",
    "plt.title(\"Distribution of Predicted Default Probabilities\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Identify borderline cases around the threshold\n",
    "# ---------------------------------------------------------\n",
    "threshold = 0.5\n",
    "borderline_mask = (y_pred_proba > threshold - 0.02) & (y_pred_proba < threshold + 0.02)\n",
    "borderline_indices = list(X_test_encoded[borderline_mask].index)\n",
    "\n",
    "print(\"Borderline indices(e.g., threshold = 0.5):\", borderline_indices[:10])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. Waterfall plot for a borderline case\n",
    "# ---------------------------------------------------------\n",
    "idx = borderline_indices[0]\n",
    "shap.plots.waterfall(shap_values[idx], max_display=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## ðŸ“Š Model Interpretation Summary for Stakeholders\n",
    "\n",
    "This analysis used SHAP (SHapley Additive exPlanations) to interpret a LightGBM model predicting default risk. The goal was to understand not just what the model predicts, but *why* â€” and to surface actionable insights for decision-makers.\n",
    "\n",
    "### ðŸ” Key Insights\n",
    "\n",
    "- **Feature Influence Is Transparent**  \n",
    "  Features like `EXT_SOURCE_2`, `DAYS_BIRTH`, and `AMT_CREDIT` show clear directional impact on risk. For example, higher `EXT_SOURCE_2` scores consistently reduce predicted risk.\n",
    "\n",
    "- **Categorical Features Matter â€” But Require Care**  \n",
    "  Organization type, education level, and family status all influence predictions. However, LightGBMâ€™s internal handling of categorical splits requires preprocessing for SHAP compatibility.\n",
    "\n",
    "- **Individual Explanations Build Trust**  \n",
    "  Force plots and waterfall plots (where successful) reveal which features push a prediction toward or away from default â€” enabling case-level auditability.\n",
    "\n",
    "- **Threshold Analysis Supports Business Decisions**  \n",
    "  By visualizing predicted probabilities and inspecting borderline cases, we can set risk thresholds that balance caution with opportunity.\n",
    "\n",
    "### âš ï¸ Known Limitations\n",
    "\n",
    "- Some SHAP plots failed due to unencoded string features (e.g. `\"Cash loans\"`). Fixes are known and can be applied post-presentation.\n",
    "- SHAPâ€™s newer APIs may conflict with LightGBMâ€™s categorical handling â€” we used the stable `TreeExplainer` workaround.\n",
    "\n",
    "### âœ… Next Steps\n",
    "\n",
    "- Encode all categorical features before SHAP analysis  \n",
    "- Extend interpretability to fairness, calibration, and business rule overlays  \n",
    "- Use SHAP insights to refine model thresholds and improve stakeholder alignment\n",
    "\n",
    "This notebook provides a transparent, interpretable foundation for risk modeling â€” ready to support Mondayâ€™s stakeholder presentation and future model governance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
